{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use Kaggle's Random Accts of Pizza classification task for my project.\n",
    "\n",
    "https://www.kaggle.com/c/random-acts-of-pizza\n",
    "\n",
    "Let's start by importing some libraries and loading the data into an ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [giver_username_if_known, in_test_set, number_of_downvotes_of_request_at_retrieval, number_of_upvotes_of_request_at_retrieval, post_was_edited, request_id, request_number_of_comments_at_retrieval, request_text, request_text_edit_aware, request_title, requester_account_age_in_days_at_request, requester_account_age_in_days_at_retrieval, requester_days_since_first_post_on_raop_at_request, requester_days_since_first_post_on_raop_at_retrieval, requester_number_of_comments_at_request, requester_number_of_comments_at_retrieval, requester_number_of_comments_in_raop_at_request, requester_number_of_comments_in_raop_at_retrieval, requester_number_of_posts_at_request, requester_number_of_posts_at_retrieval, requester_number_of_posts_on_raop_at_request, requester_number_of_posts_on_raop_at_retrieval, requester_number_of_subreddits_at_request, requester_received_pizza, requester_subreddits_at_request, requester_upvotes_minus_downvotes_at_request, requester_upvotes_minus_downvotes_at_retrieval, requester_upvotes_plus_downvotes_at_request, requester_upvotes_plus_downvotes_at_retrieval, requester_user_flair, requester_username, unix_timestamp_of_request, unix_timestamp_of_request_utc]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "import urllib\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# download the data and extract the tarball \n",
    "tf = urllib.URLopener()\n",
    "\n",
    "# change the url to http from https if you get a urllib error\n",
    "tf.retrieve(\"https://cs.stanford.edu/~althoff/raop-dataset/pizza_request_dataset.tar.gz\", \"pizza.tar.gz\")\n",
    "\n",
    "tar = tarfile.open(\"pizza.tar.gz\", \"r:gz\")\n",
    "for name in tar.getnames():\n",
    "    if name == \"pizza_request_dataset/pizza_request_dataset.json\":\n",
    "        member = tar.getmember(name)\n",
    "        f = tar.extractfile(member)\n",
    "        if f is not None:\n",
    "            json_data = f.read()\n",
    "\n",
    "# convert data to a pandas dataframe\n",
    "pizza_df = pd.read_json(json_data)\n",
    "print(pizza_df[:0])\n",
    "pizza_df = np.asarray(pizza_df)\n",
    "\n",
    "# shuffle the data\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(pizza_df.shape[0]))\n",
    "pizza_df = pizza_df[shuffle]\n",
    "\n",
    "# extract test and train data and labels\n",
    "dev_data, dev_labels = np.delete(pizza_df[:500], 23, axis=1), [x for x in pizza_df[:500, 23]]\n",
    "test_data, test_labels = np.delete(pizza_df[500:1000], 23, axis=1), [x for x in pizza_df[500:1000, 23]]\n",
    "train_data, train_labels = np.delete(pizza_df[1000:], 23, axis=1), [x for x in pizza_df[1000:, 23]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a baseline\n",
    "\n",
    "Let's establish a baseline using BernoulliNB, MultinomialNB and LogisticRegression. We will use just the post text (corresponding to column 7 in pizza_df) and the \"requester_received_pizza\" outcome (True, False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# define a helper function to perform the analysis \n",
    "def perform_analysis(train_data, train_labels, dev_data, dev_features, \n",
    "                     vectorizer=CountVectorizer(), clf = BernoulliNB(), \n",
    "                     gsc_params = {}):\n",
    "    \n",
    "    train_data_features = vectorizer.fit_transform(train_data)\n",
    "    dev_data_features = vectorizer.transform(dev_data)\n",
    "    \n",
    "    print(\"RESULTS FOR Default %s : -------------------------------\" % (clf))\n",
    "    clf.fit(train_data_features, train_labels)\n",
    "    print(\"f1_score: %s\\naccuracy_score: %s\\nroc_auc_score: %s\\n\" \n",
    "              % (metrics.f1_score(dev_labels, clf.predict(dev_data_features)), \n",
    "          metrics.accuracy_score(dev_labels, clf.predict(dev_data_features)), \n",
    "                metrics.roc_auc_score(dev_labels, clf.predict(dev_data_features))))\n",
    "    \n",
    "    print(\"Calculating Cross Vaidation Scores: \")\n",
    "    scores = cross_validation.cross_val_score(clf, train_data_features, train_labels, cv=10, scoring='f1_weighted')\n",
    "    print(\"Scores: %s\\n\" % (scores))\n",
    "    \n",
    "    # Search for the best estimator\n",
    "    print(\"STARTING GRID SEARCH...\")\n",
    "    gsc = GridSearchCV(clf, gsc_params, n_jobs=-1)\n",
    "    gsc.fit(train_data_features, train_labels)\n",
    "    print(\"Best estimator: %s\\nBest alpha: %s\\nBest score: %s\\nScorer function: %s\\n\" \n",
    "          % (gsc.best_estimator_, gsc.best_params_, gsc.best_score_, gsc.scorer_))\n",
    "    # return gsc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB using CountVectorizer\n",
      "RESULTS FOR Default BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) : -------------------------------\n",
      "f1_score: 0.305555555556\n",
      "accuracy_score: 0.7\n",
      "roc_auc_score: 0.554981518817\n",
      "\n",
      "Calculating Cross Vaidation Scores: \n",
      "Scores: [ 0.68923924  0.69364719  0.68049658  0.67924009  0.69507729  0.69611298\n",
      "  0.67960775  0.66109026  0.68012268  0.67949566]\n",
      "\n",
      "STARTING GRID SEARCH...\n",
      "Best estimator: BernoulliNB(alpha=0.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "Best alpha: {'alpha': 0.0}\n",
      "Best score: 0.737315350032\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n",
      "BernoulliNB using TfidfVectorizer\n",
      "RESULTS FOR Default BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) : -------------------------------\n",
      "f1_score: 0.212290502793\n",
      "accuracy_score: 0.718\n",
      "roc_auc_score: 0.531207997312\n",
      "\n",
      "Calculating Cross Vaidation Scores: \n",
      "Scores: [ 0.6948353   0.69313005  0.70509014  0.69313005  0.70155229  0.67149621\n",
      "  0.67980691  0.65757883  0.68676729  0.67902348]\n",
      "\n",
      "STARTING GRID SEARCH...\n",
      "Best estimator: BernoulliNB(alpha=0.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "Best alpha: {'alpha': 0.0}\n",
      "Best score: 0.736887176194\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BernoulliNB using CountVectorizer\n",
    "print(\"BernoulliNB using CountVectorizer\")\n",
    "perform_analysis(train_data[:, 7], train_labels, dev_data[:, 7], dev_labels, \n",
    "                 vectorizer=CountVectorizer(), clf = BernoulliNB(), \n",
    "                 gsc_params = {'alpha': np.arange(0, 1, 0.01)})\n",
    "\n",
    "# BernoulliNB using TfidfVectorizer\n",
    "print(\"BernoulliNB using TfidfVectorizer\")\n",
    "perform_analysis(train_data[:, 7], train_labels, dev_data[:, 7], dev_labels, \n",
    "                 vectorizer=TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english'), clf = BernoulliNB(), \n",
    "                 gsc_params = {'alpha': np.arange(0, 1, 0.01)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB using CountVectorizer\n",
      "RESULTS FOR Default MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) : -------------------------------\n",
      "f1_score: 0.0915032679739\n",
      "accuracy_score: 0.722\n",
      "roc_auc_score: 0.503150201613\n",
      "\n",
      "Calculating Cross Vaidation Scores: \n",
      "Scores: [ 0.69658503  0.67541664  0.67977306  0.67645383  0.69491832  0.6602577\n",
      "  0.6839763   0.63693178  0.64502397  0.6718563 ]\n",
      "\n",
      "STARTING GRID SEARCH...\n",
      "Best estimator: MultinomialNB(alpha=0.98999999999999999, class_prior=None, fit_prior=True)\n",
      "Best alpha: {'alpha': 0.98999999999999999}\n",
      "Best score: 0.731749090131\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n",
      "MultinomialNB using TfidfVectorizer\n",
      "RESULTS FOR Default MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) : -------------------------------\n",
      "f1_score: 0.0\n",
      "accuracy_score: 0.744\n",
      "roc_auc_score: 0.5\n",
      "\n",
      "Calculating Cross Vaidation Scores: \n",
      "Scores: [ 0.64573692  0.64468864  0.64573692  0.64573692  0.64790979  0.64790979\n",
      "  0.64790979  0.64719664  0.64719664  0.64719664]\n",
      "\n",
      "STARTING GRID SEARCH...\n",
      "Best estimator: MultinomialNB(alpha=0.91000000000000003, class_prior=None, fit_prior=True)\n",
      "Best alpha: {'alpha': 0.91000000000000003}\n",
      "Best score: 0.75294369514\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB using CountVectorizer\n",
    "print(\"MultinomialNB using CountVectorizer\")\n",
    "perform_analysis(train_data[:, 7], train_labels, dev_data[:, 7], dev_labels, \n",
    "                 vectorizer=CountVectorizer(), clf = MultinomialNB(), \n",
    "                 gsc_params = {'alpha': np.arange(0, 1, 0.01)})\n",
    "\n",
    "# MultinomialNB using TfidfVectorizer\n",
    "print(\"MultinomialNB using TfidfVectorizer\")\n",
    "perform_analysis(train_data[:, 7], train_labels, dev_data[:, 7], dev_labels, \n",
    "                 vectorizer=TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english'), clf = MultinomialNB(), \n",
    "                 gsc_params = {'alpha': np.arange(0, 1, 0.01)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression using CountVectorizer\n",
      "RESULTS FOR Default LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) : -------------------------------\n",
      "f1_score: 0.209523809524\n",
      "accuracy_score: 0.668\n",
      "roc_auc_score: 0.50529233871\n",
      "\n",
      "Calculating Cross Vaidation Scores: \n",
      "Scores: [ 0.71056113  0.70374342  0.68475426  0.70022931  0.66436359  0.68405106\n",
      "  0.69450078  0.657613    0.68159917  0.70261076]\n",
      "\n",
      "STARTING GRID SEARCH...\n",
      "Best estimator: LogisticRegression(C=0.02, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best alpha: {'C': 0.02}\n",
      "Best score: 0.754656390495\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n",
      "LogisticRegression using TfidfVectorizer\n",
      "RESULTS FOR Default LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) : -------------------------------\n",
      "f1_score: 0.0296296296296\n",
      "accuracy_score: 0.738\n",
      "roc_auc_score: 0.501092069892\n",
      "\n",
      "Calculating Cross Vaidation Scores: \n",
      "Scores: [ 0.66988649  0.67487664  0.65482947  0.67362827  0.66645446  0.66645446\n",
      "  0.66874512  0.65741875  0.67469176  0.66339267]\n",
      "\n",
      "STARTING GRID SEARCH...\n",
      "Best estimator: LogisticRegression(C=0.76000000000000001, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Best alpha: {'C': 0.76000000000000001}\n",
      "Best score: 0.75594091201\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression using CountVectorizer\n",
    "print(\"LogisticRegression using CountVectorizer\")\n",
    "perform_analysis(train_data[:, 7], train_labels, dev_data[:, 7], dev_labels, \n",
    "                 vectorizer=CountVectorizer(), clf = LogisticRegression(), \n",
    "                 gsc_params = {'C': np.arange(0.01, 1, 0.01)})\n",
    "\n",
    "# LogisticRegression using TfidfVectorizer\n",
    "print(\"LogisticRegression using TfidfVectorizer\")\n",
    "perform_analysis(train_data[:, 7], train_labels, dev_data[:, 7], dev_labels, \n",
    "                 vectorizer=TfidfVectorizer(), clf = LogisticRegression(), \n",
    "                 gsc_params = {'C': np.arange(0.01, 1, 0.01)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier using CountVectorizer\n",
      "RESULTS FOR Default KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') : -------------------------------\n",
      "f1_score: 0.103896103896\n",
      "accuracy_score: 0.724\n",
      "roc_auc_score: 0.507056451613\n",
      "\n",
      "Calculating Cross Vaidation Scores: \n",
      "Scores: [ 0.66880342  0.65150464  0.67415834  0.66070829  0.65334379  0.66829823\n",
      "  0.64546451  0.65698709  0.66896721  0.64462871]\n",
      "\n",
      "STARTING GRID SEARCH...\n",
      "Best estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=52, p=2,\n",
      "           weights='uniform')\n",
      "Best alpha: {'n_neighbors': 52}\n",
      "Best score: 0.75315778206\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n",
      "KNeighborsClassifier using TfidfVectorizer\n",
      "RESULTS FOR Default KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') : -------------------------------\n",
      "f1_score: 0.0285714285714\n",
      "accuracy_score: 0.728\n",
      "roc_auc_score: 0.494371639785\n",
      "\n",
      "Calculating Cross Vaidation Scores: \n",
      "Scores: [ 0.65019014  0.66067982  0.65678407  0.64669785  0.6409107   0.64967935\n",
      "  0.63943053  0.64476271  0.64362025  0.64296913]\n",
      "\n",
      "STARTING GRID SEARCH...\n",
      "Best estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
      "           weights='uniform')\n",
      "Best alpha: {'n_neighbors': 12}\n",
      "Best score: 0.75294369514\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier using CountVectorizer\n",
    "print(\"KNeighborsClassifier using CountVectorizer\")\n",
    "perform_analysis(train_data[:, 7], train_labels, dev_data[:, 7], dev_labels, \n",
    "                 vectorizer=CountVectorizer(), clf = KNeighborsClassifier(), \n",
    "                 gsc_params = {'n_neighbors': np.arange(1, 100, 1)})\n",
    "\n",
    "# KNeighborsClassifier using TfidfVectorizer\n",
    "print(\"KNeighborsClassifier using TfidfVectorizer\")\n",
    "perform_analysis(train_data[:, 7], train_labels, dev_data[:, 7], dev_labels, \n",
    "                 vectorizer=TfidfVectorizer(), clf = KNeighborsClassifier(), \n",
    "                 gsc_params = {'n_neighbors': np.arange(1, 100, 1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, using default options with KNearestNeighbors, BernoulliNB, MultinomialNB and LogisticRegression yielded accuracy better that random guessing. All three classifiers scored between approximately 70% to 75%. We can use this as a baseline and look to improve the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A better baseline?\n",
    "\n",
    "I suppose 75% accuracy is a good baseline to start with. Let's look to improve this in the next steps. I will try a pipeline as the first attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Pipeline (chaining classifiers)\n",
    "\n",
    "Let's see if chained transformation via CountVectorizer and TfiddfTransformer, followed by LogisticRegression, improves the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   35.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        st...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best alpha: {'vect__ngram_range': (1, 1), 'tfidf__use_idf': True, 'vect__max_df': 0.5}\n",
      "Best score: 0.756797259687\n",
      "Scorer function: <function _passthrough_scorer at 0x0000000008C88A58>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# let's learn about pipelines; they will come in handy for ensembles\n",
    "# ****code below is taken from scikit-learn's documentation on pipelines****\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (2, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    #'clf__alpha': (0.00001, 0.000001),\n",
    "    #'clf__penalty': ('l2', 'elasticnet'),\n",
    "    # 'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "# **** end of code taken from scikit-learn's documentation ****\n",
    "\n",
    "gsc = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "gsc.fit(train_data[:, 7], train_labels)\n",
    "print(\"Best estimator: %s\\nBest alpha: %s\\nBest score: %s\\nScorer function: %s\\n\" \n",
    "      % (gsc.best_estimator_, gsc.best_params_, gsc.best_score_, gsc.scorer_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Randomized trees and Ensembles\n",
    "Let's first look at the results of randomized trees and then use an ensemble (the VotingClassifier). Let's also convert user's subreddits to a \"bag of words\" and run that through randomized trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier score: 0.744\n",
      "ExtraTreesClassifier roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Extremely Randomized Trees\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "vectorizer = HashingVectorizer(n_features=1000, analyzer='word', norm='l2', stop_words='english')\n",
    "train_data_features = vectorizer.fit_transform(train_data[:, 7])\n",
    "train_labels = [x for x in pizza_df[1000:, 23]]\n",
    "dev_data_features = vectorizer.transform(dev_data[:, 7])\n",
    "dev_labels = [x for x in pizza_df[:500, 23]]\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=250, max_depth=None, \n",
    "                          min_samples_split=2, random_state=0, \n",
    "                          criterion='entropy')\n",
    "clf.fit(train_data_features, train_labels)\n",
    "\n",
    "print(\"ExtraTreesClassifier score: %s\" % (clf.score(dev_data_features, dev_labels)))\n",
    "\n",
    "print(\"ExtraTreesClassifier roc_auc_score: %s\" % (metrics.roc_auc_score(dev_labels, clf.predict(dev_data_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier score: 0.722\n",
      "ExtraTreesClassifier roc_auc_score: 0.485215053763\n"
     ]
    }
   ],
   "source": [
    "# Extremely Randomized Trees\n",
    "# With subreddit membership as a bag of words\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "vectorizer = HashingVectorizer(n_features=1000, analyzer='word', norm='l2', stop_words='english')\n",
    "\n",
    "td = [' '.join(x) for x in train_data[:, 23]]\n",
    "dd = [' '.join(x) for x in dev_data[:, 23]]\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(td)\n",
    "train_labels = [x for x in pizza_df[1000:, 23]]\n",
    "dev_data_features = vectorizer.transform(dd)\n",
    "dev_labels = [x for x in pizza_df[:500, 23]]\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=250, max_depth=None, \n",
    "                          min_samples_split=2, random_state=0, \n",
    "                          criterion='entropy')\n",
    "clf.fit(train_data_features, train_labels)\n",
    "\n",
    "print(\"ExtraTreesClassifier score: %s\" % (clf.score(dev_data_features, dev_labels)))\n",
    "print(\"ExtraTreesClassifier roc_auc_score: %s\" % (metrics.roc_auc_score(dev_labels, clf.predict(dev_data_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier accuracy score: 0.748\n",
      "VotingClassifier roc_auc_score: 0.512936827957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "dev_data, dev_labels = np.delete(pizza_df[:500], 23, axis=1), [x for x in pizza_df[:500, 23]]\n",
    "train_data, train_labels = np.delete(pizza_df[1000:], 23, axis=1), [x for x in pizza_df[1000:, 23]]\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(train_data[:, 7])\n",
    "dev_data_features = vectorizer.transform(dev_data[:, 7])\n",
    "\n",
    "clf1 = KNeighborsClassifier()\n",
    "clf2 = BernoulliNB()\n",
    "clf3 = LogisticRegression()\n",
    "clf4 = ExtraTreesClassifier(n_estimators=250, max_depth=None, \n",
    "                          min_samples_split=2, random_state=0, \n",
    "                          criterion='entropy')\n",
    "vclf1 = VotingClassifier(estimators=[('knn', clf1), ('bnb', clf2), ('lr', clf3), ('etc', clf4)], voting='hard')\n",
    "\n",
    "vclf1.fit(train_data_features, train_labels)\n",
    "print(\"VotingClassifier accuracy score: %s\" % (metrics.accuracy_score(dev_labels, vclf1.predict(dev_data_features))))\n",
    "print(\"VotingClassifier roc_auc_score: %s\" % (metrics.roc_auc_score(dev_labels, vclf1.predict(dev_data_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'm surprised to see that the ExtraTreesClassifier returns 72.2% accuracy for the subreddit membership which is marginally lower than the accuracy from the post itself (74%).\n",
    "However, the overall accuracy is similar to the results of individual classifiers used earlier. It appears that a bag of words approach alone is not going to cut it. \n",
    "\n",
    "Let's look to improve upon this by first using a FeatureUnion on post words and subreddits (bag of words, yet again). After that I will look to expand the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Unions to improve the baseline\n",
    "\n",
    "\n",
    "... to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline accuracy score: 0.748\n",
      "Pipeline roc_auc_score: 0.5078125\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ItemSelector class COPIED VERBATIM from:\n",
    "# http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "post_train_data = train_data[:, 7]\n",
    "post_dev_data = dev_data[:, 7] \n",
    "\n",
    "title_train_data = train_data[:, 9]\n",
    "title_dev_data = dev_data[:, 9] \n",
    "\n",
    "\n",
    "subreddits_train_data = [' '.join(x) for x in train_data[:, 23]] \n",
    "subreddits_dev_data = [' '.join(x) for x in dev_data[:, 23]]\n",
    "\n",
    "pipeline_train_data = {'title': title_train_data, \n",
    "                       'posts': post_train_data, \n",
    "                       'subreddits': subreddits_train_data}\n",
    "\n",
    "pipeline_dev_data = {'title': title_dev_data, \n",
    "                     'posts': post_dev_data, \n",
    "                     'subreddits': subreddits_dev_data}\n",
    "pipeline = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                    ('title', Pipeline([\n",
    "                                ('selector', ItemSelector(key='title')), \n",
    "                                ('cv', CountVectorizer()), \n",
    "                            ])),\n",
    "                    \n",
    "                    ('subreddits', Pipeline([\n",
    "                                ('selector', ItemSelector(key='subreddits')), \n",
    "                                ('cv', CountVectorizer()), \n",
    "                            ])),\n",
    "                    ('post', Pipeline([\n",
    "                                ('selector', ItemSelector(key='posts')), \n",
    "                                ('vect', TfidfVectorizer(min_df=0.01, stop_words='english')), \n",
    "                                ('best', TruncatedSVD(n_components=50)), \n",
    "                            ])), \n",
    "                    \n",
    "                ], \n",
    "            transformer_weights={\n",
    "                    'title': 0.5,\n",
    "                    'subreddits': 0.4, \n",
    "                    'post': 0.7, \n",
    "                }, \n",
    "            )), \n",
    "        ('clf', ExtraTreesClassifier(n_estimators=250, max_depth=None, \n",
    "                          min_samples_split=2, random_state=0, \n",
    "                          criterion='entropy'))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(pipeline_train_data, train_labels)\n",
    "\n",
    "print(\"Pipeline accuracy score: %s\" % (metrics.accuracy_score(dev_labels, pipeline.predict(pipeline_dev_data))))\n",
    "print(\"Pipeline roc_auc_score: %s\" % (metrics.roc_auc_score(dev_labels, pipeline.predict(pipeline_dev_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now ain't that a b\\*\\*\\*\\*\\!\n",
    "\n",
    "It looks like a bag-of-words approach is not going to cut it. But all is not lost yet. We can start adding some other features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paying it forward, reciprocity, give & take\n",
    "\n",
    "Let's evaluate notions of give and take and reciprocity in the posts. May be the potential for getting something in return affects people's decision to buy some random person a pizza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of NOT getting pizza: 0.75\n",
      "Prob. of NOT getting pizza given reciprocity: 0.20 \n",
      "\n",
      "Prob. of getting pizza: 0.25\n",
      "Prob. of getting pizza given reciprocity: 0.26 \n",
      "\n",
      "Prob. of reciprocity in all posts: 0.22 \n",
      "\n",
      "Posterior prob. of getting pizza given reciprocity: 0.29\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "reciprocity_terms = ['pay it forward', 'paying it forward', 'forward',  \n",
    "                     'reciprocate', 'give back', 'trade', 'pay it back'\n",
    "                    'pic', 'pics', 'story', 'stories']\n",
    "\n",
    "def is_phrase_found(phrase_list, target_text):\n",
    "    found = False\n",
    "    for t in reciprocity_terms:\n",
    "        if t in target_text:\n",
    "            found = True\n",
    "            break\n",
    "    return found\n",
    "\n",
    "def get_phrase_freq(phrase_list, target_text):\n",
    "    found = 0\n",
    "    for t in reciprocity_terms:\n",
    "        for d in target_text:\n",
    "            if t in d:\n",
    "                found += 1\n",
    "    return found\n",
    "\n",
    "def calc_odds(data, query_terms):\n",
    "    f = 0.\n",
    "    for d in data:\n",
    "        if(is_phrase_found(query_terms, d)):\n",
    "            f += 1\n",
    "    return f / len(data)\n",
    "\n",
    "train_gotpizza = pizza_df[1000:][pizza_df[1000:][:, 23] == True][:, 7]\n",
    "train_nopizza = pizza_df[1000:][pizza_df[1000:][:, 23] == False][:, 7]\n",
    "dev_gotpizza = pizza_df[:500][pizza_df[:500][:, 23] == True][:, 7]\n",
    "dev_nopizza = pizza_df[:500][pizza_df[:500][:, 23] == False][:, 7]\n",
    "\n",
    "print(\"Prob. of NOT getting pizza: %.2f\" % (len(train_nopizza) / float(len(train_data))))\n",
    "p1 = calc_odds(train_nopizza, reciprocity_terms)\n",
    "print(\"Prob. of NOT getting pizza given reciprocity: %.2f \\n\" % p1)\n",
    "\n",
    "p2 = len(train_gotpizza) / float(len(train_data))\n",
    "print(\"Prob. of getting pizza: %.2f\" % p2)\n",
    "p3 = calc_odds(train_gotpizza, reciprocity_terms)\n",
    "print(\"Prob. of getting pizza given reciprocity: %.2f \\n\" % p3)\n",
    "\n",
    "p4 = calc_odds(train_data[:, 7], reciprocity_terms)\n",
    "print(\"Prob. of reciprocity in all posts: %.2f \\n\" % p4)\n",
    "\n",
    "# Calculate the posterior odds of the desired Event (E), that is getting a pizza\n",
    "# P(E | x) = p(x | E) * p(E) / p(x) \n",
    "print(\"Posterior prob. of getting pizza given reciprocity: %.2f\" % ( p3 * p2 / p4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that reciprocity has a bit of an effect on the likelihood of a post getting a pizza, let's add that as a feature to our pipeline. So may be we can hand adjust the probability of getting a pizza for posts that contain a notion of reciprocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior accuracy score: 0.746\n",
      "Posterior accuracy score: 0.746\n",
      "Posterior roc_auc_score score: 0.506468413978\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 3))\n",
    "train_data_features = vectorizer.fit_transform(train_data[:, 7])\n",
    "train_labels = [x for x in pizza_df[1000:, 23]]\n",
    "\n",
    "dev_data_features = vectorizer.transform(dev_data[:, 7])\n",
    "dev_labels = [x for x in pizza_df[:500, 23]]\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=250, max_depth=None, \n",
    "                          min_samples_split=2, random_state=0, \n",
    "                          criterion='entropy')\n",
    "\n",
    "et.fit(train_data_features, train_labels)\n",
    "print(\"Prior accuracy score: %s\" % metrics.accuracy_score(dev_labels, et.predict(dev_data_features)))\n",
    "\n",
    "dev_probs = et.predict_proba(dev_data_features)\n",
    "for i, t in enumerate(dev_data[:, 7]):\n",
    "    if(is_phrase_found(reciprocity_terms, t)):\n",
    "        dev_probs[i][1] = dev_probs[i][1] * 1.16\n",
    "# write our own prediction\n",
    "dev_predicted_labels = []\n",
    "for i, (f, t) in enumerate(dev_probs):\n",
    "    if(t > f): \n",
    "        dev_predicted_labels.append(True)\n",
    "    else:\n",
    "        dev_predicted_labels.append(False)\n",
    "\n",
    "print(\"Posterior accuracy score: %s\" % metrics.accuracy_score(dev_labels, dev_predicted_labels))\n",
    "print(\"Posterior roc_auc_score score: %s\" % metrics.roc_auc_score(dev_labels, dev_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reciproc_train_data = []\n",
    "for t in train_data[:, 7]:\n",
    "    reciproc_train_data.append(is_phrase_found(reciprocity_terms, t))\n",
    "\n",
    "reciproc_dev_data = []\n",
    "for t in dev_data[:, 7]:\n",
    "    reciproc_dev_data.append(is_phrase_found(reciprocity_terms, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# selected numeric columns from train_data and dev_data\n",
    "# number represents the column index starting at 0\n",
    "# 2 \t number_of_downvotes_of_request_at_retrieval\n",
    "# 6 \t request_number_of_comments_at_retrieval\n",
    "# 10\t requester_account_age_in_days_at_request\n",
    "# 12\t requester_days_since_first_post_on_raop_at_request\n",
    "# 14\t requester_number_of_comments_at_request\n",
    "# 16\t requester_number_of_comments_in_raop_at_request\n",
    "# 18\t requester_number_of_posts_at_request\n",
    "# 20\t requester_number_of_posts_on_raop_at_request\n",
    "# 22\t requester_number_of_subreddits_at_request\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "train_numeric_data = train_data[:, [2, 6, 10, 12, 14, 16, 18, 20, 22]]\n",
    "train_labels = [x for x in pizza_df[1000:, 23]]\n",
    "\n",
    "dev_numeric_data = dev_data[:, [2, 6, 10, 12, 14, 16, 18, 20, 22]]\n",
    "dev_labels = [x for x in pizza_df[:500, 23]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762\n",
      "0.58639952957\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_numeric_data, train_labels)\n",
    "print(metrics.accuracy_score(dev_labels, lr.predict(dev_numeric_data)))\n",
    "print(metrics.roc_auc_score(dev_labels, lr.predict(dev_numeric_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722\n",
      "0.549269153226\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier()\n",
    "et.fit(train_numeric_data, train_labels)\n",
    "print(metrics.accuracy_score(dev_labels, et.predict(dev_numeric_data)))\n",
    "print(metrics.roc_auc_score(dev_labels, et.predict(dev_numeric_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n",
      "0.622521841398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(train_numeric_data, train_labels)\n",
    "print(metrics.accuracy_score(dev_labels, gb.predict(dev_numeric_data)))\n",
    "print(metrics.roc_auc_score(dev_labels, gb.predict(dev_numeric_data))) # the best score we got all day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_text_features = vectorizer.fit_transform(train_data[:, 7]).todense()\n",
    "dev_text_features = vectorizer.transform(dev_data[:, 7]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_train_features = np.concatenate((train_text_features, train_numeric_data), axis=1)\n",
    "all_dev_features = np.concatenate((dev_text_features, dev_numeric_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756\n",
      "0.605426747312\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(all_train_features, train_labels)\n",
    "print(metrics.accuracy_score(dev_labels, gb.predict(all_dev_features)))\n",
    "print(metrics.roc_auc_score(dev_labels, gb.predict(all_dev_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "atf_normalized = preprocessing.normalize(all_train_features, norm='l2')\n",
    "adf_normalized = preprocessing.normalize(all_dev_features, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734\n",
      "0.516339045699\n"
     ]
    }
   ],
   "source": [
    "gb = ExtraTreesClassifier()\n",
    "gb.fit(atf_normalized, train_labels)\n",
    "print(metrics.accuracy_score(dev_labels, gb.predict(adf_normalized)))\n",
    "print(metrics.roc_auc_score(dev_labels, gb.predict(adf_normalized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier accuracy score: 0.744\n",
      "VotingClassifier roc_auc_score: 0.505124327957\n"
     ]
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier()\n",
    "clf2 = BernoulliNB()\n",
    "clf3 = LogisticRegression()\n",
    "clf4 = ExtraTreesClassifier(n_estimators=250, max_depth=None, \n",
    "                          min_samples_split=2, random_state=0, \n",
    "                          criterion='entropy')\n",
    "vclf2 = VotingClassifier(estimators=[('knn', clf1), ('bnb', clf2), ('lr', clf3), ('etc', clf4)], voting='hard')\n",
    "\n",
    "\n",
    "vclf2.fit(atf_normalized, train_labels)\n",
    "print(\"VotingClassifier accuracy score: %s\" % (metrics.accuracy_score(dev_labels, vclf2.predict(adf_normalized))))\n",
    "print(\"VotingClassifier roc_auc_score: %s\" % (metrics.roc_auc_score(dev_labels, vclf2.predict(adf_normalized))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier accuracy score: 0.748\n",
      "VotingClassifier roc_auc_score: 0.510374663978\n"
     ]
    }
   ],
   "source": [
    "clf5 = GradientBoostingClassifier()\n",
    "vclf3 = VotingClassifier(estimators=[('lr', clf3), ('etc', clf4), ('gb', clf5)], voting='hard')\n",
    "\n",
    "\n",
    "vclf3.fit(atf_normalized, train_labels)\n",
    "print(\"VotingClassifier accuracy score: %s\" % (metrics.accuracy_score(dev_labels, vclf3.predict(adf_normalized))))\n",
    "print(\"VotingClassifier roc_auc_score: %s\" % (metrics.roc_auc_score(dev_labels, vclf3.predict(adf_normalized))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
